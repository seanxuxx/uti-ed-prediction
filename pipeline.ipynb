{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/xx/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import zipfile\n",
    "import numpy.typing as npt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import wandb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (LabelEncoder, MinMaxScaler, OneHotEncoder,\n",
    "                                   OrdinalEncoder, StandardScaler)\n",
    "from sklearn.svm import SVC\n",
    "from torchsummary import summary\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "    DEVICE_N_WORKERS = 4\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    DEVICE_N_WORKERS = 0\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epochs': 30,\n",
    "    'batch_size': 32,\n",
    "    'init_lr': 5e-4,\n",
    "    'dropout_rate': 0.2,\n",
    "    'scheduler_factor': 0.8,\n",
    "    'scheduler_patience': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = os.path.join(os.getcwd(), 'data', 'S1File.csv')\n",
    "metadata_filename = os.path.join(os.getcwd(), 'data', 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_filename)\n",
    "metadata = pd.read_csv(metadata_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = metadata.variable.to_list()\n",
    "label = 'UCX_abnormal'  # UCX test result\n",
    "diagnosis = 'UTI_diag'  # ED diagnosis\n",
    "\n",
    "# Map UCX and clinical diagnosis to int\n",
    "df[label] = df[label].map({'yes': 1, 'no': 0})\n",
    "df[diagnosis] = df[diagnosis].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Reorder columns\n",
    "df = df[[label] + [diagnosis] + features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    First, drop the columns with not_reported values > 10%\n",
    "    Then, drop observations with not_reported or other values\n",
    "    return cleaned dataframe\n",
    "    \"\"\"\n",
    "    # Drop the columns with not_reported values > 10%\n",
    "    drop = []\n",
    "    demo = ['age', 'gender', 'race', 'ethnicity', 'lang',\n",
    "            'employStatus', 'maritalStatus', 'chief_complaint']\n",
    "    cols = [i for i in df.columns if i not in demo]\n",
    "    for col in cols:\n",
    "        ratio = df[col][df[col] == 'not_reported'].count()/df.shape[0]*100\n",
    "        if ratio > 0.1:\n",
    "            drop.append(col)\n",
    "    df = df.drop(labels=drop, axis=1)\n",
    "\n",
    "    # Drop observations with not_reported or other values\n",
    "    df= df[~df.apply(lambda row: row =='not_reported').any(axis=1)]\n",
    "    df= df[~df.apply(lambda row: row =='other').any(axis=1)]\n",
    "    df= df[~df.apply(lambda row: row =='4+').any(axis=1)]\n",
    "\n",
    "    # Convert numeric features to float\n",
    "    num = ['ua_ph', 'ua_spec_grav', 'age']\n",
    "    for col in num:\n",
    "        mean = df[(df[col] != 'not_reported') & (df[col]!= 'other')][col].astype(\n",
    "            'float').mean()\n",
    "        df[col] = df[col].replace('not_reported', mean)\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df: pd.DataFrame) -> tuple[pd.DataFrame, ColumnTransformer]:\n",
    "    \"\"\"\n",
    "    Input the cleaned dataframe,\n",
    "    OneHotEncode the categorical (non-ordinal) attributes,\n",
    "    OrdinalEncode the ordinal attributes\n",
    "    return the final dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    other = ['ua_ph', 'ua_spec_grav', 'age']\n",
    "    ord = ['ua_blood', 'ua_glucose', 'ua_ketones', 'ua_leuk', 'ua_protein']\n",
    "    onehot = ['chief_complaint', 'race', 'ethnicity',\n",
    "              'maritalStatus', 'employStatus']\n",
    "    label = [i for i in df.columns if i not in ord+other+onehot]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('onehot', OneHotEncoder(), onehot),\n",
    "            ('label', OrdinalEncoder(), label),\n",
    "            ('ordinal', OrdinalEncoder(categories=[\n",
    "             ['negative', 'small', 'moderate', 'large']]* len(ord)), ord)\n",
    "        ])\n",
    "\n",
    "    transformed = preprocessor.fit_transform(df)\n",
    "\n",
    "    onehot_col_names = preprocessor.named_transformers_[\n",
    "        'onehot'].get_feature_names_out(onehot)\n",
    "    new_column_names = list(onehot_col_names) + label + ord\n",
    "    # Preserve the original index\n",
    "    df_transformed = pd.DataFrame(\n",
    "        transformed, columns=new_column_names, index=df.index)  # type: ignore\n",
    "\n",
    "    df_final = pd.concat([df[other], df_transformed], axis=1)\n",
    "\n",
    "    return df_final, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UCX_abnormal</th>\n",
       "      <th>UTI_diag</th>\n",
       "      <th>ua_blood</th>\n",
       "      <th>ua_color</th>\n",
       "      <th>ua_glucose</th>\n",
       "      <th>ua_ketones</th>\n",
       "      <th>ua_leuk</th>\n",
       "      <th>ua_nitrite</th>\n",
       "      <th>ua_ph</th>\n",
       "      <th>ua_protein</th>\n",
       "      <th>...</th>\n",
       "      <th>MISCELLANEOUS_MEDICAL_SUPPLIES__DEVICES__NON_DRUG</th>\n",
       "      <th>MUSCLE_RELAXANTS</th>\n",
       "      <th>PRE_NATAL_VITAMINS</th>\n",
       "      <th>PSYCHOTHERAPEUTIC_DRUGS</th>\n",
       "      <th>SEDATIVE_HYPNOTICS</th>\n",
       "      <th>SKIN_PREPS</th>\n",
       "      <th>SMOKING_DETERRENTS</th>\n",
       "      <th>THYROID_PREPS</th>\n",
       "      <th>UNCLASSIFIED_DRUG_PRODUCTS</th>\n",
       "      <th>VITAMINS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>yellow</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>small</td>\n",
       "      <td>negative</td>\n",
       "      <td>7.5</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>yellow</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>small</td>\n",
       "      <td>negative</td>\n",
       "      <td>5.0</td>\n",
       "      <td>small</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>yellow</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>large</td>\n",
       "      <td>negative</td>\n",
       "      <td>5.5</td>\n",
       "      <td>small</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>orange</td>\n",
       "      <td>negative</td>\n",
       "      <td>small</td>\n",
       "      <td>small</td>\n",
       "      <td>positive</td>\n",
       "      <td>6.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>yellow</td>\n",
       "      <td>negative</td>\n",
       "      <td>large</td>\n",
       "      <td>small</td>\n",
       "      <td>negative</td>\n",
       "      <td>6.0</td>\n",
       "      <td>small</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UCX_abnormal  UTI_diag  ua_blood ua_color ua_glucose ua_ketones ua_leuk  \\\n",
       "0             1         1  negative   yellow   negative   negative   small   \n",
       "2             1         0  negative   yellow   negative   negative   small   \n",
       "3             1         1  negative   yellow   negative   negative   large   \n",
       "4             0         0  negative   orange   negative      small   small   \n",
       "5             1         0     large   yellow   negative      large   small   \n",
       "\n",
       "  ua_nitrite  ua_ph ua_protein  ...  \\\n",
       "0   negative    7.5   negative  ...   \n",
       "2   negative    5.0      small  ...   \n",
       "3   negative    5.5      small  ...   \n",
       "4   positive    6.0   moderate  ...   \n",
       "5   negative    6.0      small  ...   \n",
       "\n",
       "   MISCELLANEOUS_MEDICAL_SUPPLIES__DEVICES__NON_DRUG MUSCLE_RELAXANTS  \\\n",
       "0                                                 No               No   \n",
       "2                                                 No               No   \n",
       "3                                                 No               No   \n",
       "4                                                 No               No   \n",
       "5                                                 No               No   \n",
       "\n",
       "   PRE_NATAL_VITAMINS PSYCHOTHERAPEUTIC_DRUGS SEDATIVE_HYPNOTICS SKIN_PREPS  \\\n",
       "0                  No                      No                 No         No   \n",
       "2                  No                     Yes                Yes         No   \n",
       "3                  No                      No                 No         No   \n",
       "4                  No                      No                 No         No   \n",
       "5                  No                      No                 No         No   \n",
       "\n",
       "  SMOKING_DETERRENTS THYROID_PREPS UNCLASSIFIED_DRUG_PRODUCTS VITAMINS  \n",
       "0                 No            No                         No       No  \n",
       "2                 No           Yes                        Yes       No  \n",
       "3                 No            No                         No      Yes  \n",
       "4                 No            No                         No       No  \n",
       "5                 No            No                         No       No  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = trim_missing(df)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature X shape: (59792, 153)\n",
      "Label Y shape: (59792, 2), where\n",
      "\tthe first column is true label (UCX_abnormal)\n",
      "\tthe second column is ed diagnosis (UTI_diag)\n"
     ]
    }
   ],
   "source": [
    "X, encoder = encode_features(df_cleaned.iloc[:, 2:])\n",
    "Y = df_cleaned.iloc[:, :2]\n",
    "print(f'Feature X shape: {X.shape}')\n",
    "print(f'Label Y shape: {Y.shape}, where'\n",
    "      f'\\n\\tthe first column is true label ({label})'\n",
    "      f'\\n\\tthe second column is ed diagnosis ({diagnosis})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ua_ph</th>\n",
       "      <th>ua_spec_grav</th>\n",
       "      <th>age</th>\n",
       "      <th>chief_complaint_ABDOMINAL PAIN</th>\n",
       "      <th>chief_complaint_ALTERED MENTAL STATUS</th>\n",
       "      <th>chief_complaint_BACK PAIN</th>\n",
       "      <th>chief_complaint_CHEST PAIN</th>\n",
       "      <th>chief_complaint_DIZZINESS</th>\n",
       "      <th>chief_complaint_DYSURIA</th>\n",
       "      <th>chief_complaint_EMESIS</th>\n",
       "      <th>...</th>\n",
       "      <th>SKIN_PREPS</th>\n",
       "      <th>SMOKING_DETERRENTS</th>\n",
       "      <th>THYROID_PREPS</th>\n",
       "      <th>UNCLASSIFIED_DRUG_PRODUCTS</th>\n",
       "      <th>VITAMINS</th>\n",
       "      <th>ua_blood</th>\n",
       "      <th>ua_glucose</th>\n",
       "      <th>ua_ketones</th>\n",
       "      <th>ua_leuk</th>\n",
       "      <th>ua_protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1.020</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.016</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>1.016</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.030</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.030</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ua_ph  ua_spec_grav   age  chief_complaint_ABDOMINAL PAIN  \\\n",
       "0    7.5         1.020  83.0                             1.0   \n",
       "2    5.0         1.016  78.0                             0.0   \n",
       "3    5.5         1.016  84.0                             0.0   \n",
       "4    6.0         1.030  55.0                             1.0   \n",
       "5    6.0         1.030  47.0                             1.0   \n",
       "\n",
       "   chief_complaint_ALTERED MENTAL STATUS  chief_complaint_BACK PAIN  \\\n",
       "0                                    0.0                        0.0   \n",
       "2                                    1.0                        0.0   \n",
       "3                                    0.0                        0.0   \n",
       "4                                    0.0                        0.0   \n",
       "5                                    0.0                        0.0   \n",
       "\n",
       "   chief_complaint_CHEST PAIN  chief_complaint_DIZZINESS  \\\n",
       "0                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         0.0                        0.0   \n",
       "5                         0.0                        0.0   \n",
       "\n",
       "   chief_complaint_DYSURIA  chief_complaint_EMESIS  ...  SKIN_PREPS  \\\n",
       "0                      0.0                     0.0  ...         0.0   \n",
       "2                      0.0                     0.0  ...         0.0   \n",
       "3                      0.0                     0.0  ...         0.0   \n",
       "4                      0.0                     0.0  ...         0.0   \n",
       "5                      0.0                     0.0  ...         0.0   \n",
       "\n",
       "   SMOKING_DETERRENTS  THYROID_PREPS  UNCLASSIFIED_DRUG_PRODUCTS  VITAMINS  \\\n",
       "0                 0.0            0.0                         0.0       0.0   \n",
       "2                 0.0            1.0                         1.0       0.0   \n",
       "3                 0.0            0.0                         0.0       1.0   \n",
       "4                 0.0            0.0                         0.0       0.0   \n",
       "5                 0.0            0.0                         0.0       0.0   \n",
       "\n",
       "   ua_blood  ua_glucose  ua_ketones  ua_leuk  ua_protein  \n",
       "0       0.0         0.0         0.0      1.0         0.0  \n",
       "2       0.0         0.0         0.0      1.0         1.0  \n",
       "3       0.0         0.0         0.0      3.0         1.0  \n",
       "4       0.0         0.0         1.0      1.0         2.0  \n",
       "5       3.0         0.0         3.0      1.0         1.0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UCX_abnormal</th>\n",
       "      <th>UTI_diag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UCX_abnormal  UTI_diag\n",
       "0             1         1\n",
       "2             1         0\n",
       "3             1         1\n",
       "4             0         0\n",
       "5             1         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "y_train, y_test = Y_train[label], Y_test[label]\n",
    "\n",
    "assert y_train.name == label\n",
    "assert y_test.name == label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35874, 11959, 11959)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train.shape), len(y_val.shape), len(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        assert len(X) == len(y), 'inconsistent shape between X and y'\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "        self.length = len(X)\n",
    "        self.n_feature = X.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        feature = torch.FloatTensor(self.features[i])\n",
    "        label = torch.FloatTensor([self.labels[i]])\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X: np.ndarray):\n",
    "        self.features = X\n",
    "        self.length = len(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        feature = torch.FloatTensor(self.features[i])\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainDataset(X=X_train.values, y=y_train.values)\n",
    "val_data = TrainDataset(X=X_val.values, y=y_val.values)\n",
    "test_data = TestDataset(X=X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  32\n",
      "Train dataset samples = 35874, batches = 1121\n",
      "Validation dataset samples = 11959, batches = 373\n",
      "Test dataset samples = 11959, batches = 374\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           num_workers=DEVICE_N_WORKERS,\n",
    "                                           batch_size=config['batch_size'],\n",
    "                                           pin_memory=True,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data,\n",
    "                                         num_workers=0,\n",
    "                                         batch_size=config['batch_size'],\n",
    "                                         pin_memory=True,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                          num_workers=0,\n",
    "                                          batch_size=config['batch_size'],\n",
    "                                          pin_memory=True,\n",
    "                                          shuffle=False)\n",
    "\n",
    "print(\"Batch size: \", config['batch_size'])\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(\n",
    "    train_data.__len__(), len(train_loader)))\n",
    "print(\"Validation dataset samples = {}, batches = {}\".format(\n",
    "    val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(\n",
    "    test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 153]) torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# Testing code to check if your data loaders are working\n",
    "for i, (feature, label) in enumerate(train_loader):\n",
    "    print(feature.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, dropout_rate: float):\n",
    "\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(512, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(2048, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(128, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size=train_data.n_feature,\n",
    "           dropout_rate=config['dropout_rate']).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3966, dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_weight = (df.UCX_abnormal == 0).sum() / (df.UCX_abnormal == 1).sum()\n",
    "pos_weight = torch.tensor(pos_weight)\n",
    "pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['init_lr'])\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                       factor=config['scheduler_factor'],\n",
    "                                                       patience=config['scheduler_patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"c3a06f318f071ae7444755a93fa8a5cbff1f6a86\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ydenlz9v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">nn</strong> at: <a href='https://wandb.ai/seanxx/map/runs/ydenlz9v' target=\"_blank\">https://wandb.ai/seanxx/map/runs/ydenlz9v</a><br/> View project at: <a href='https://wandb.ai/seanxx/map' target=\"_blank\">https://wandb.ai/seanxx/map</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241002_213751-ydenlz9v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ydenlz9v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/xx/uti-ed-prediction/wandb/run-20241002_213814-glonsij0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seanxx/map/runs/glonsij0' target=\"_blank\">nn</a></strong> to <a href='https://wandb.ai/seanxx/map' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seanxx/map' target=\"_blank\">https://wandb.ai/seanxx/map</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seanxx/map/runs/glonsij0' target=\"_blank\">https://wandb.ai/seanxx/map/runs/glonsij0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    # name='nn',\n",
    "    reinit=True,  # Allows reinitalizing runs when you re-run this cell\n",
    "    # id     = \"y28t31uz\", ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project=\"map\",  # Project should be created in your wandb account\n",
    "    config=config  # Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/xx/uti-ed-prediction/wandb/run-20241002_213814-glonsij0/files/model_arch.txt']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save your model architecture as a string with str(model)\n",
    "model_arch = str(model)\n",
    "\n",
    "# Save it in a txt file\n",
    "arch_file = open(\"model_arch.txt\", \"w\")\n",
    "file_write = arch_file.write(model_arch)\n",
    "arch_file.close()\n",
    "\n",
    "# log it in your wandb run with wandb.save()\n",
    "wandb.save('model_arch.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    return total_loss, total_acc\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0, 0\n",
    "\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True,\n",
    "                     leave=False, position=0, desc='Train')\n",
    "\n",
    "    for i, (feature, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        feature = feature.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        # Forward Propagation\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            # print(feature.device)\n",
    "            # print(next(model.parameters()).device)\n",
    "            logits = model(feature)\n",
    "            loss = criterion(logits, label)\n",
    "\n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # GD\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Record\n",
    "        prediction = (logits >= 0.5).int()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += torch.sum(prediction == label).item() / logits.shape[0]\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "                              acc=\"{:.04f}%\".format(float(total_acc*100 / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "        # Release memory\n",
    "        del feature, label, logits, prediction\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    total_loss /= len(dataloader)\n",
    "    total_acc /= len(dataloader)\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader, criterion):\n",
    "    \"\"\"\n",
    "    return total_loss, total_acc, precision, recall, f1\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    total_loss, total_acc = 0, 0\n",
    "    predictions, labels = [], []\n",
    "\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True,\n",
    "                     leave=False, position=0, desc='Val')\n",
    "\n",
    "    for i, (feature, label) in enumerate(dataloader):\n",
    "        feature = feature.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        # Forward Propagation\n",
    "        with torch.inference_mode():\n",
    "            logits = model(feature)\n",
    "            loss = criterion(logits, label)\n",
    "\n",
    "        # Record\n",
    "        prediction = (logits >= 0.5).int()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += torch.sum(prediction == label).item() / logits.shape[0]\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "                              acc=\"{:.04f}%\".format(float(total_acc*100 / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "        labels.extend(label.tolist())\n",
    "        predictions.extend(prediction.tolist())\n",
    "\n",
    "        # Release memory\n",
    "        del feature, label, logits, prediction\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    total_loss /= len(dataloader)\n",
    "    total_acc /= len(dataloader)\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    return (total_loss, total_acc, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, feature in enumerate(tqdm(test_loader)):\n",
    "\n",
    "            feature = feature.to(DEVICE)\n",
    "            logits = model(feature)\n",
    "            prediction = (logits >= 0.5).int()\n",
    "            predictions.extend(prediction.tolist())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace(model, X_train, X_test, y_train, y_test,\n",
    "                     ljust_len=30):\n",
    "    print('Training accuracy: {}'.format(\n",
    "        \"%.4f\" % model.score(X_train, y_train)))\n",
    "\n",
    "    male, female = X_test.gender == 1, X_test.gender == 0\n",
    "    print('Test accuracy:\\n\\t{}{}\\n\\t{}{}\\n\\t{}{}'.format(\n",
    "        'General population'.ljust(ljust_len),\n",
    "        \"%.4f\" % model.score(X_test, y_test),\n",
    "        'Male'.ljust(ljust_len),\n",
    "        \"%.4f\" % model.score(X_test[male], y_test[male]),\n",
    "        'Female'.ljust(ljust_len),\n",
    "        \"%.4f\" % model.score(X_test[female], y_test[female])))\n",
    "\n",
    "    employ_cols = X_test.columns[X_test.columns.str.contains('employStatus')]\n",
    "    for employ_col in employ_cols:\n",
    "        rows = X_test[employ_col] == 1\n",
    "        print('\\t{}{}'.format(\n",
    "            employ_col.split('_')[-1].ljust(ljust_len),\n",
    "            \"%.4f\" % model.score(X_test[rows], y_test[rows])))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print('\\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(file_path, model, optimizer, scaler, scheduler,\n",
    "                    epoch, train_acc, val_acc, precision, recall, f1):\n",
    "\n",
    "    checkpoint = {'epoch': epoch,\n",
    "                  'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'scaler_state_dict': scaler.state_dict(),\n",
    "                  'scheduler_state_dict': scheduler.state_dict(),\n",
    "                  'train_accuray': train_acc, 'val_accuray': val_acc,\n",
    "                  'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    torch.save(checkpoint, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 77.8211%\tTrain Loss 0.9747\t Learning Rate 0.0005000\n",
      "\tVal Acc 79.1136%\tVal Loss 0.9658\n",
      "\tVal Precison 0.5520\tRecall 0.6417\tF1 0.5935\n",
      "Best model saved at epoch 1\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 79.6387%\tTrain Loss 0.9564\t Learning Rate 0.0005000\n",
      "\tVal Acc 79.7922%\tVal Loss 0.9650\n",
      "\tVal Precison 0.5690\tRecall 0.6167\tF1 0.5919\n",
      "Best model saved at epoch 2\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 80.2715%\tTrain Loss 0.9539\t Learning Rate 0.0005000\n",
      "\tVal Acc 81.5181%\tVal Loss 0.9622\n",
      "\tVal Precison 0.6218\tRecall 0.5670\tF1 0.5931\n",
      "Best model saved at epoch 3\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 80.9768%\tTrain Loss 0.9507\t Learning Rate 0.0005000\n",
      "\tVal Acc 80.8981%\tVal Loss 0.9563\n",
      "\tVal Precison 0.5924\tRecall 0.6283\tF1 0.6099\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 80.4053%\tTrain Loss 0.9499\t Learning Rate 0.0005000\n",
      "\tVal Acc 78.6947%\tVal Loss 0.9606\n",
      "\tVal Precison 0.5408\tRecall 0.6855\tF1 0.6046\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 80.8095%\tTrain Loss 0.9475\t Learning Rate 0.0005000\n",
      "\tVal Acc 79.9263%\tVal Loss 0.9567\n",
      "\tVal Precison 0.5671\tRecall 0.6555\tF1 0.6081\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 81.4647%\tTrain Loss 0.9455\t Learning Rate 0.0005000\n",
      "\tVal Acc 80.4373%\tVal Loss 0.9543\n",
      "\tVal Precison 0.5771\tRecall 0.6615\tF1 0.6164\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 81.6877%\tTrain Loss 0.9427\t Learning Rate 0.0005000\n",
      "\tVal Acc 81.4930%\tVal Loss 0.9574\n",
      "\tVal Precison 0.6118\tRecall 0.6047\tF1 0.6083\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 81.1803%\tTrain Loss 0.9445\t Learning Rate 0.0005000\n",
      "\tVal Acc 80.9987%\tVal Loss 0.9549\n",
      "\tVal Precison 0.5921\tRecall 0.6439\tF1 0.6169\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 81.6598%\tTrain Loss 0.9398\t Learning Rate 0.0005000\n",
      "\tVal Acc 82.2470%\tVal Loss 0.9593\n",
      "\tVal Precison 0.6483\tRecall 0.5525\tF1 0.5966\n",
      "Best model saved at epoch 10\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.1309%\tTrain Loss 0.9384\t Learning Rate 0.0004000\n",
      "\tVal Acc 81.7108%\tVal Loss 0.9543\n",
      "\tVal Precison 0.6166\tRecall 0.6090\tF1 0.6127\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.3762%\tTrain Loss 0.9353\t Learning Rate 0.0004000\n",
      "\tVal Acc 80.8981%\tVal Loss 0.9522\n",
      "\tVal Precison 0.5888\tRecall 0.6499\tF1 0.6178\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.7303%\tTrain Loss 0.9334\t Learning Rate 0.0004000\n",
      "\tVal Acc 80.4290%\tVal Loss 0.9547\n",
      "\tVal Precison 0.5774\tRecall 0.6580\tF1 0.6150\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.5546%\tTrain Loss 0.9333\t Learning Rate 0.0004000\n",
      "\tVal Acc 81.5851%\tVal Loss 0.9584\n",
      "\tVal Precison 0.6147\tRecall 0.6030\tF1 0.6088\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.0481%\tTrain Loss 0.9304\t Learning Rate 0.0004000\n",
      "\tVal Acc 80.9233%\tVal Loss 0.9557\n",
      "\tVal Precison 0.5911\tRecall 0.6396\tF1 0.6144\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.0258%\tTrain Loss 0.9293\t Learning Rate 0.0003200\n",
      "\tVal Acc 81.6940%\tVal Loss 0.9598\n",
      "\tVal Precison 0.6248\tRecall 0.5748\tF1 0.5987\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.5917%\tTrain Loss 0.9271\t Learning Rate 0.0003200\n",
      "\tVal Acc 81.6689%\tVal Loss 0.9553\n",
      "\tVal Precison 0.6150\tRecall 0.6111\tF1 0.6130\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.7087%\tTrain Loss 0.9239\t Learning Rate 0.0003200\n",
      "\tVal Acc 80.2111%\tVal Loss 0.9551\n",
      "\tVal Precison 0.5726\tRecall 0.6590\tF1 0.6128\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.9067%\tTrain Loss 0.9219\t Learning Rate 0.0002560\n",
      "\tVal Acc 82.2554%\tVal Loss 0.9567\n",
      "\tVal Precison 0.6409\tRecall 0.5758\tF1 0.6066\n",
      "Best model saved at epoch 19\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.9875%\tTrain Loss 0.9207\t Learning Rate 0.0002560\n",
      "\tVal Acc 79.7168%\tVal Loss 0.9573\n",
      "\tVal Precison 0.5614\tRecall 0.6689\tF1 0.6105\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.5423%\tTrain Loss 0.9193\t Learning Rate 0.0002560\n",
      "\tVal Acc 81.2081%\tVal Loss 0.9586\n",
      "\tVal Precison 0.6054\tRecall 0.6005\tF1 0.6029\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.6231%\tTrain Loss 0.9168\t Learning Rate 0.0002048\n",
      "\tVal Acc 81.8532%\tVal Loss 0.9569\n",
      "\tVal Precison 0.6246\tRecall 0.5920\tF1 0.6079\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.1360%\tTrain Loss 0.9138\t Learning Rate 0.0002048\n",
      "\tVal Acc 81.0824%\tVal Loss 0.9567\n",
      "\tVal Precison 0.5983\tRecall 0.6202\tF1 0.6091\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.2643%\tTrain Loss 0.9134\t Learning Rate 0.0002048\n",
      "\tVal Acc 81.5851%\tVal Loss 0.9559\n",
      "\tVal Precison 0.6147\tRecall 0.6030\tF1 0.6088\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.1862%\tTrain Loss 0.9124\t Learning Rate 0.0001638\n",
      "\tVal Acc 81.7611%\tVal Loss 0.9588\n",
      "\tVal Precison 0.6262\tRecall 0.5765\tF1 0.6003\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.5403%\tTrain Loss 0.9100\t Learning Rate 0.0001638\n",
      "\tVal Acc 81.2919%\tVal Loss 0.9570\n",
      "\tVal Precison 0.6053\tRecall 0.6111\tF1 0.6082\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.3591%\tTrain Loss 0.9095\t Learning Rate 0.0001638\n",
      "\tVal Acc 81.6605%\tVal Loss 0.9572\n",
      "\tVal Precison 0.6166\tRecall 0.6033\tF1 0.6099\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.8162%\tTrain Loss 0.9081\t Learning Rate 0.0001311\n",
      "\tVal Acc 81.9119%\tVal Loss 0.9629\n",
      "\tVal Precison 0.6384\tRecall 0.5504\tF1 0.5912\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.9445%\tTrain Loss 0.9065\t Learning Rate 0.0001311\n",
      "\tVal Acc 81.5684%\tVal Loss 0.9616\n",
      "\tVal Precison 0.6210\tRecall 0.5755\tF1 0.5974\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.9640%\tTrain Loss 0.9060\t Learning Rate 0.0001311\n",
      "\tVal Acc 81.5684%\tVal Loss 0.9582\n",
      "\tVal Precison 0.6161\tRecall 0.5952\tF1 0.6055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>██████████▆▆▆▆▆▅▅▅▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇█▇███</td></tr><tr><td>train_loss</td><td>█▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▂▃▇▅▁▃▄▇▆█▇▅▄▇▅▇▇▄█▃▆▇▆▇▇▆▇▇▇▇</td></tr><tr><td>val_f1</td><td>▂▁▂▆▅▅█▅█▂▇█▇▆▇▃▇▇▅▆▄▅▆▆▃▅▆▁▃▅</td></tr><tr><td>val_loss</td><td>██▆▃▅▃▂▄▂▅▂▁▂▄▃▅▃▃▃▄▄▃▃▃▄▃▄▇▆▄</td></tr><tr><td>val_precison</td><td>▂▃▆▄▁▃▃▆▄█▆▄▃▆▄▆▆▃█▂▅▆▅▆▇▅▆▇▆▆</td></tr><tr><td>val_recall</td><td>▆▄▂▅█▆▇▄▆▁▄▆▇▄▆▂▄▇▂▇▄▃▅▄▂▄▄▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.00013</td></tr><tr><td>train_acc</td><td>85.96398</td></tr><tr><td>train_loss</td><td>0.90601</td></tr><tr><td>val_acc</td><td>81.56836</td></tr><tr><td>val_f1</td><td>0.60545</td></tr><tr><td>val_loss</td><td>0.95825</td></tr><tr><td>val_precison</td><td>0.61606</td></tr><tr><td>val_recall</td><td>0.5952</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">nn</strong> at: <a href='https://wandb.ai/seanxx/map/runs/glonsij0' target=\"_blank\">https://wandb.ai/seanxx/map/runs/glonsij0</a><br/> View project at: <a href='https://wandb.ai/seanxx/map' target=\"_blank\">https://wandb.ai/seanxx/map</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241002_213814-glonsij0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
    "    train_loss, train_acc = train(model,\n",
    "                                  train_loader,\n",
    "                                  criterion,\n",
    "                                  optimizer,\n",
    "                                  scaler)\n",
    "    val_loss, val_acc, precision, recall, f1 = eval(model,\n",
    "                                                    val_loader,\n",
    "                                                    criterion)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(\n",
    "        train_acc*100, train_loss, curr_lr))\n",
    "    print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(\n",
    "        val_acc*100, val_loss))\n",
    "    print(\"\\tVal Precison {:.04f}\\tRecall {:.04f}\\tF1 {:.04f}\".format(\n",
    "        precision, recall, f1))\n",
    "\n",
    "    wandb.log({\n",
    "        'lr': curr_lr,\n",
    "        'train_acc': train_acc*100,\n",
    "        'train_loss': train_loss,\n",
    "        'val_acc': val_acc*100,\n",
    "        'val_loss': val_loss,\n",
    "        'val_precison': precision,\n",
    "        'val_recall': recall,\n",
    "        'val_f1': f1\n",
    "    })\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    if (val_acc > best_score):\n",
    "        best_score = val_acc\n",
    "        save_checkpoint(f'{run.id}_best_model.pt', model, optimizer, scaler, scheduler,\n",
    "                        epoch, train_acc, val_acc, precision, recall, f1)\n",
    "        print(f'Best model saved at epoch {epoch}')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 179/374 [00:00<00:00, 234.32it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mlen\u001b[39m(y_pred)\n",
      "Cell \u001b[0;32mIn[39], line 10\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(test_loader)):\n\u001b[1;32m      9\u001b[0m     feature \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 10\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m (logits \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\n\u001b[1;32m     12\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mextend(prediction\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1616\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1616\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1619\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/integration/torch/wandb_torch.py:113\u001b[0m, in \u001b[0;36mTorchHistory.add_log_parameters_hook.<locals>.<lambda>\u001b[0;34m(mod, inp, outp)\u001b[0m\n\u001b[1;32m    110\u001b[0m log_track_params \u001b[38;5;241m=\u001b[39m log_track_init(log_freq)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     hook \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mregister_forward_hook(\n\u001b[0;32m--> 113\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m mod, inp, outp: \u001b[43mparameter_log_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_track_params\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_handles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m prefix] \u001b[38;5;241m=\u001b[39m hook\n\u001b[1;32m    118\u001b[0m     module\u001b[38;5;241m.\u001b[39m_wandb_hook_names\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameters/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m prefix)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/integration/torch/wandb_torch.py:108\u001b[0m, in \u001b[0;36mTorchHistory.add_log_parameters_hook.<locals>.parameter_log_hook\u001b[0;34m(module, input_, output, log_track)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     data \u001b[38;5;241m=\u001b[39m parameter\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_tensor_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/wandb/integration/torch/wandb_torch.py:254\u001b[0m, in \u001b[0;36mTorchHistory.log_tensor_stats\u001b[0;34m(self, tensor, name)\u001b[0m\n\u001b[1;32m    251\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(tensor_np)\n\u001b[1;32m    252\u001b[0m     bins \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(bins_np)\n\u001b[0;32m--> 254\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m(\n\u001b[1;32m    255\u001b[0m     {name: wandb\u001b[38;5;241m.\u001b[39mHistogram(np_histogram\u001b[38;5;241m=\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mtolist(), bins\u001b[38;5;241m.\u001b[39mtolist()))},\n\u001b[1;32m    256\u001b[0m     commit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_log'"
     ]
    }
   ],
   "source": [
    "y_pred = test(model, test_loader)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(f'{wandb.run.id}_best_model.pt',\n",
    "                model, optimizer, scaler, scheduler,\n",
    "                epoch, train_acc, val_acc, precision, recall, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
