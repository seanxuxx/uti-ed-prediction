{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchsummaryX in /home/xx/.local/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: torch in /home/xx/.local/lib/python3.9/site-packages (from torchsummaryX) (2.4.1)\n",
      "Requirement already satisfied: numpy in /home/xx/.local/lib/python3.9/site-packages (from torchsummaryX) (2.0.2)\n",
      "Requirement already satisfied: pandas in /home/xx/.local/lib/python3.9/site-packages (from torchsummaryX) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/xx/.local/lib/python3.9/site-packages (from pandas->torchsummaryX) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/xx/.local/lib/python3.9/site-packages (from pandas->torchsummaryX) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/xx/.local/lib/python3.9/site-packages (from pandas->torchsummaryX) (2024.2)\n",
      "Requirement already satisfied: filelock in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/xx/.local/lib/python3.9/site-packages (from torch->torchsummaryX) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/xx/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchsummaryX) (12.6.77)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->torchsummaryX) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/xx/.local/lib/python3.9/site-packages (from jinja2->torch->torchsummaryX) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/xx/.local/lib/python3.9/site-packages (from sympy->torch->torchsummaryX) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/xx/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import zipfile\n",
    "import numpy.typing as npt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import wandb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import (LabelEncoder, MinMaxScaler, OneHotEncoder,\n",
    "                                   OrdinalEncoder, StandardScaler)\n",
    "from sklearn.svm import SVC\n",
    "from torchsummary import summary\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "    DEVICE_N_WORKERS = 4\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    DEVICE_N_WORKERS = 0\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epochs': 30,\n",
    "    'batch_size': 64,\n",
    "    'init_lr': 1e-3,\n",
    "    'dropout_rate': 0.2,\n",
    "    'scheduler_factor': 0.5,\n",
    "    'scheduler_patience': 3,\n",
    "    'architecture': 'diamond'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = os.path.join(os.getcwd(), 'data', 'S1File.csv')\n",
    "metadata_filename = os.path.join(os.getcwd(), 'data', 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_filename)\n",
    "metadata = pd.read_csv(metadata_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = metadata.variable.to_list()\n",
    "label = 'UCX_abnormal'  # UCX test result\n",
    "diagnosis = 'UTI_diag'  # ED diagnosis\n",
    "\n",
    "# Map UCX and clinical diagnosis to int\n",
    "df[label] = df[label].map({'yes': 1, 'no': 0})\n",
    "df[diagnosis] = df[diagnosis].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Reorder columns\n",
    "df = df[[label] + [diagnosis] + features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_missing(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    First, drop the columns with not_reported values > 10%\n",
    "    Then, drop observations with not_reported or other values\n",
    "    return cleaned dataframe\n",
    "    \"\"\"\n",
    "    # Drop the columns with not_reported values > 10%\n",
    "    drop = []\n",
    "    demo = ['age', 'gender', 'race', 'ethnicity', 'lang',\n",
    "            'employStatus', 'maritalStatus', 'chief_complaint']\n",
    "    cols = [i for i in df.columns if i not in demo]\n",
    "    for col in cols:\n",
    "        ratio = df[col][df[col] == 'not_reported'].count()/df.shape[0]*100\n",
    "        if ratio > 0.1:\n",
    "            drop.append(col)\n",
    "    df = df.drop(labels=drop, axis=1)\n",
    "\n",
    "    # Drop observations with not_reported or other values\n",
    "    df= df[~df.apply(lambda row: row =='not_reported').any(axis=1)]\n",
    "    df= df[~df.apply(lambda row: row =='other').any(axis=1)]\n",
    "    df= df[~df.apply(lambda row: row =='4+').any(axis=1)]\n",
    "\n",
    "    # Convert numeric features to float\n",
    "    num = ['ua_ph', 'ua_spec_grav', 'age']\n",
    "    for col in num:\n",
    "        mean = df[(df[col] != 'not_reported') & (df[col]!= 'other')][col].astype(\n",
    "            'float').mean()\n",
    "        df[col] = df[col].replace('not_reported', mean)\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df: pd.DataFrame) -> tuple[pd.DataFrame, ColumnTransformer]:\n",
    "    \"\"\"\n",
    "    Input the cleaned dataframe,\n",
    "    OneHotEncode the categorical (non-ordinal) attributes,\n",
    "    OrdinalEncode the ordinal attributes\n",
    "    return the final dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    other = ['ua_ph', 'ua_spec_grav', 'age']\n",
    "    ord = ['ua_blood', 'ua_glucose', 'ua_ketones', 'ua_leuk', 'ua_protein']\n",
    "    onehot = ['chief_complaint', 'race', 'ethnicity',\n",
    "              'maritalStatus', 'employStatus']\n",
    "    label = [i for i in df.columns if i not in ord+other+onehot]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('onehot', OneHotEncoder(), onehot),\n",
    "            ('label', OrdinalEncoder(), label),\n",
    "            ('ordinal', OrdinalEncoder(categories=[\n",
    "             ['negative', 'small', 'moderate', 'large']]* len(ord)), ord)\n",
    "        ])\n",
    "\n",
    "    transformed = preprocessor.fit_transform(df)\n",
    "\n",
    "    onehot_col_names = preprocessor.named_transformers_[\n",
    "        'onehot'].get_feature_names_out(onehot)\n",
    "    new_column_names = list(onehot_col_names) + label + ord\n",
    "    # Preserve the original index\n",
    "    df_transformed = pd.DataFrame(\n",
    "        transformed, columns=new_column_names, index=df.index)  # type: ignore\n",
    "\n",
    "    df_final = pd.concat([df[other], df_transformed], axis=1)\n",
    "\n",
    "    return df_final, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UCX_abnormal</th>\n",
       "      <th>UTI_diag</th>\n",
       "      <th>ua_blood</th>\n",
       "      <th>ua_color</th>\n",
       "      <th>ua_glucose</th>\n",
       "      <th>ua_ketones</th>\n",
       "      <th>ua_leuk</th>\n",
       "      <th>ua_nitrite</th>\n",
       "      <th>ua_ph</th>\n",
       "      <th>ua_protein</th>\n",
       "      <th>...</th>\n",
       "      <th>MISCELLANEOUS_MEDICAL_SUPPLIES__DEVICES__NON_DRUG</th>\n",
       "      <th>MUSCLE_RELAXANTS</th>\n",
       "      <th>PRE_NATAL_VITAMINS</th>\n",
       "      <th>PSYCHOTHERAPEUTIC_DRUGS</th>\n",
       "      <th>SEDATIVE_HYPNOTICS</th>\n",
       "      <th>SKIN_PREPS</th>\n",
       "      <th>SMOKING_DETERRENTS</th>\n",
       "      <th>THYROID_PREPS</th>\n",
       "      <th>UNCLASSIFIED_DRUG_PRODUCTS</th>\n",
       "      <th>VITAMINS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>yellow</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>small</td>\n",
       "      <td>negative</td>\n",
       "      <td>7.5</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>yellow</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>small</td>\n",
       "      <td>negative</td>\n",
       "      <td>5.0</td>\n",
       "      <td>small</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>yellow</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>large</td>\n",
       "      <td>negative</td>\n",
       "      <td>5.5</td>\n",
       "      <td>small</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>orange</td>\n",
       "      <td>negative</td>\n",
       "      <td>small</td>\n",
       "      <td>small</td>\n",
       "      <td>positive</td>\n",
       "      <td>6.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "      <td>yellow</td>\n",
       "      <td>negative</td>\n",
       "      <td>large</td>\n",
       "      <td>small</td>\n",
       "      <td>negative</td>\n",
       "      <td>6.0</td>\n",
       "      <td>small</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UCX_abnormal  UTI_diag  ua_blood ua_color ua_glucose ua_ketones ua_leuk  \\\n",
       "0             1         1  negative   yellow   negative   negative   small   \n",
       "2             1         0  negative   yellow   negative   negative   small   \n",
       "3             1         1  negative   yellow   negative   negative   large   \n",
       "4             0         0  negative   orange   negative      small   small   \n",
       "5             1         0     large   yellow   negative      large   small   \n",
       "\n",
       "  ua_nitrite  ua_ph ua_protein  ...  \\\n",
       "0   negative    7.5   negative  ...   \n",
       "2   negative    5.0      small  ...   \n",
       "3   negative    5.5      small  ...   \n",
       "4   positive    6.0   moderate  ...   \n",
       "5   negative    6.0      small  ...   \n",
       "\n",
       "   MISCELLANEOUS_MEDICAL_SUPPLIES__DEVICES__NON_DRUG MUSCLE_RELAXANTS  \\\n",
       "0                                                 No               No   \n",
       "2                                                 No               No   \n",
       "3                                                 No               No   \n",
       "4                                                 No               No   \n",
       "5                                                 No               No   \n",
       "\n",
       "   PRE_NATAL_VITAMINS PSYCHOTHERAPEUTIC_DRUGS SEDATIVE_HYPNOTICS SKIN_PREPS  \\\n",
       "0                  No                      No                 No         No   \n",
       "2                  No                     Yes                Yes         No   \n",
       "3                  No                      No                 No         No   \n",
       "4                  No                      No                 No         No   \n",
       "5                  No                      No                 No         No   \n",
       "\n",
       "  SMOKING_DETERRENTS THYROID_PREPS UNCLASSIFIED_DRUG_PRODUCTS VITAMINS  \n",
       "0                 No            No                         No       No  \n",
       "2                 No           Yes                        Yes       No  \n",
       "3                 No            No                         No      Yes  \n",
       "4                 No            No                         No       No  \n",
       "5                 No            No                         No       No  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = trim_missing(df)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature X shape: (59792, 153)\n",
      "Label Y shape: (59792, 2), where\n",
      "\tthe first column is true label (UCX_abnormal)\n",
      "\tthe second column is ed diagnosis (UTI_diag)\n"
     ]
    }
   ],
   "source": [
    "X, encoder = encode_features(df_cleaned.iloc[:, 2:])\n",
    "Y = df_cleaned.iloc[:, :2]\n",
    "print(f'Feature X shape: {X.shape}')\n",
    "print(f'Label Y shape: {Y.shape}, where'\n",
    "      f'\\n\\tthe first column is true label ({label})'\n",
    "      f'\\n\\tthe second column is ed diagnosis ({diagnosis})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ua_ph</th>\n",
       "      <th>ua_spec_grav</th>\n",
       "      <th>age</th>\n",
       "      <th>chief_complaint_ABDOMINAL PAIN</th>\n",
       "      <th>chief_complaint_ALTERED MENTAL STATUS</th>\n",
       "      <th>chief_complaint_BACK PAIN</th>\n",
       "      <th>chief_complaint_CHEST PAIN</th>\n",
       "      <th>chief_complaint_DIZZINESS</th>\n",
       "      <th>chief_complaint_DYSURIA</th>\n",
       "      <th>chief_complaint_EMESIS</th>\n",
       "      <th>...</th>\n",
       "      <th>SKIN_PREPS</th>\n",
       "      <th>SMOKING_DETERRENTS</th>\n",
       "      <th>THYROID_PREPS</th>\n",
       "      <th>UNCLASSIFIED_DRUG_PRODUCTS</th>\n",
       "      <th>VITAMINS</th>\n",
       "      <th>ua_blood</th>\n",
       "      <th>ua_glucose</th>\n",
       "      <th>ua_ketones</th>\n",
       "      <th>ua_leuk</th>\n",
       "      <th>ua_protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1.020</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.016</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>1.016</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.030</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.030</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ua_ph  ua_spec_grav   age  chief_complaint_ABDOMINAL PAIN  \\\n",
       "0    7.5         1.020  83.0                             1.0   \n",
       "2    5.0         1.016  78.0                             0.0   \n",
       "3    5.5         1.016  84.0                             0.0   \n",
       "4    6.0         1.030  55.0                             1.0   \n",
       "5    6.0         1.030  47.0                             1.0   \n",
       "\n",
       "   chief_complaint_ALTERED MENTAL STATUS  chief_complaint_BACK PAIN  \\\n",
       "0                                    0.0                        0.0   \n",
       "2                                    1.0                        0.0   \n",
       "3                                    0.0                        0.0   \n",
       "4                                    0.0                        0.0   \n",
       "5                                    0.0                        0.0   \n",
       "\n",
       "   chief_complaint_CHEST PAIN  chief_complaint_DIZZINESS  \\\n",
       "0                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         0.0                        0.0   \n",
       "5                         0.0                        0.0   \n",
       "\n",
       "   chief_complaint_DYSURIA  chief_complaint_EMESIS  ...  SKIN_PREPS  \\\n",
       "0                      0.0                     0.0  ...         0.0   \n",
       "2                      0.0                     0.0  ...         0.0   \n",
       "3                      0.0                     0.0  ...         0.0   \n",
       "4                      0.0                     0.0  ...         0.0   \n",
       "5                      0.0                     0.0  ...         0.0   \n",
       "\n",
       "   SMOKING_DETERRENTS  THYROID_PREPS  UNCLASSIFIED_DRUG_PRODUCTS  VITAMINS  \\\n",
       "0                 0.0            0.0                         0.0       0.0   \n",
       "2                 0.0            1.0                         1.0       0.0   \n",
       "3                 0.0            0.0                         0.0       1.0   \n",
       "4                 0.0            0.0                         0.0       0.0   \n",
       "5                 0.0            0.0                         0.0       0.0   \n",
       "\n",
       "   ua_blood  ua_glucose  ua_ketones  ua_leuk  ua_protein  \n",
       "0       0.0         0.0         0.0      1.0         0.0  \n",
       "2       0.0         0.0         0.0      1.0         1.0  \n",
       "3       0.0         0.0         0.0      3.0         1.0  \n",
       "4       0.0         0.0         1.0      1.0         2.0  \n",
       "5       3.0         0.0         3.0      1.0         1.0  \n",
       "\n",
       "[5 rows x 153 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UCX_abnormal</th>\n",
       "      <th>UTI_diag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UCX_abnormal  UTI_diag\n",
       "0             1         1\n",
       "2             1         0\n",
       "3             1         1\n",
       "4             0         0\n",
       "5             1         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "y_train, y_test = Y_train[label], Y_test[label]\n",
    "\n",
    "assert y_train.name == label\n",
    "assert y_test.name == label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35874, 11959, 11959)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train.shape), len(y_val.shape), len(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        assert len(X) == len(y), 'inconsistent shape between X and y'\n",
    "        self.features = X\n",
    "        self.labels = y\n",
    "        self.length = len(X)\n",
    "        self.n_feature = X.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        feature = torch.FloatTensor(self.features[i])\n",
    "        label = torch.FloatTensor([self.labels[i]])\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X: np.ndarray):\n",
    "        self.features = X\n",
    "        self.length = len(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        feature = torch.FloatTensor(self.features[i])\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TrainDataset(X=X_train.values, y=y_train.values)\n",
    "val_data = TrainDataset(X=X_val.values, y=y_val.values)\n",
    "test_data = TestDataset(X=X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  64\n",
      "Train dataset samples = 35874, batches = 560\n",
      "Validation dataset samples = 11959, batches = 186\n",
      "Test dataset samples = 11959, batches = 187\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                           num_workers=DEVICE_N_WORKERS,\n",
    "                                           batch_size=config['batch_size'],\n",
    "                                           pin_memory=True,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_data,\n",
    "                                         num_workers=0,\n",
    "                                         batch_size=config['batch_size'],\n",
    "                                         pin_memory=True,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                          num_workers=0,\n",
    "                                          batch_size=config['batch_size'],\n",
    "                                          pin_memory=True,\n",
    "                                          shuffle=False)\n",
    "\n",
    "print(\"Batch size: \", config['batch_size'])\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(\n",
    "    train_data.__len__(), len(train_loader)))\n",
    "print(\"Validation dataset samples = {}, batches = {}\".format(\n",
    "    val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(\n",
    "    test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 153]) torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# Testing code to check if your data loaders are working\n",
    "for i, (feature, label) in enumerate(train_loader):\n",
    "    print(feature.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, dropout_rate: float):\n",
    "\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(1024, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(2048, 4096),\n",
    "            torch.nn.BatchNorm1d(4096),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(4096, 2048),\n",
    "            torch.nn.BatchNorm1d(2048),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(2048, 1024),\n",
    "            torch.nn.BatchNorm1d(1024),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.BatchNorm1d(512),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.BatchNorm1d(256),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(128, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(input_size=train_data.n_feature,\n",
    "           dropout_rate=config['dropout_rate']).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['init_lr'])\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
    "                                                       factor=config['scheduler_factor'],\n",
    "                                                       patience=config['scheduler_patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxiaoxu1094\u001b[0m (\u001b[33mseanxx\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/xx/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"c3a06f318f071ae7444755a93fa8a5cbff1f6a86\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/xx/uti-ed-prediction/wandb/run-20241002_023427-2nsukbq8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seanxx/map/runs/2nsukbq8' target=\"_blank\">nn</a></strong> to <a href='https://wandb.ai/seanxx/map' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seanxx/map' target=\"_blank\">https://wandb.ai/seanxx/map</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seanxx/map/runs/2nsukbq8' target=\"_blank\">https://wandb.ai/seanxx/map/runs/2nsukbq8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    name='nn',\n",
    "    reinit=True,  # Allows reinitalizing runs when you re-run this cell\n",
    "    # id     = \"y28t31uz\", ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project=\"map\",  # Project should be created in your wandb account\n",
    "    config=config  # Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/xx/uti-ed-prediction/wandb/run-20241002_021515-cbkjsf4e/files/model_arch.txt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save your model architecture as a string with str(model)\n",
    "model_arch = str(model)\n",
    "\n",
    "# Save it in a txt file\n",
    "arch_file = open(\"model_arch.txt\", \"w\")\n",
    "file_write = arch_file.write(model_arch)\n",
    "arch_file.close()\n",
    "\n",
    "# log it in your wandb run with wandb.save()\n",
    "wandb.save('model_arch.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, scaler):\n",
    "    \"\"\"\n",
    "    return total_loss, total_acc\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    total_loss, total_acc = 0, 0\n",
    "\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True,\n",
    "                     leave=False, position=0, desc='Train')\n",
    "\n",
    "    for i, (feature, label) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        feature = feature.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        # Forward Propagation\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            # print(feature.device)\n",
    "            # print(next(model.parameters()).device)\n",
    "            logits = model(feature)\n",
    "            loss = criterion(logits, label)\n",
    "\n",
    "        # Backpropagation\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # GD\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Record\n",
    "        prediction = (logits >= 0.5).int()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += torch.sum(prediction == label).item() / logits.shape[0]\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "                              acc=\"{:.04f}%\".format(float(total_acc*100 / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "        # Release memory\n",
    "        del feature, label, logits, prediction\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    total_loss /= len(dataloader)\n",
    "    total_acc /= len(dataloader)\n",
    "    return total_loss, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, dataloader, criterion):\n",
    "    \"\"\"\n",
    "    return total_loss, total_acc, precision, recall, f1\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    total_loss, total_acc = 0, 0\n",
    "    predictions, labels = [], []\n",
    "\n",
    "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True,\n",
    "                     leave=False, position=0, desc='Val')\n",
    "\n",
    "    for i, (feature, label) in enumerate(dataloader):\n",
    "        feature = feature.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        # Forward Propagation\n",
    "        with torch.inference_mode():\n",
    "            logits = model(feature)\n",
    "            loss = criterion(logits, label)\n",
    "\n",
    "        # Record\n",
    "        prediction = (logits >= 0.5).int()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += torch.sum(prediction == label).item() / logits.shape[0]\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "                              acc=\"{:.04f}%\".format(float(total_acc*100 / (i + 1))))\n",
    "        batch_bar.update()\n",
    "\n",
    "        labels.extend(label.tolist())\n",
    "        predictions.extend(prediction.tolist())\n",
    "\n",
    "        # Release memory\n",
    "        del feature, label, logits, prediction\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "\n",
    "    total_loss /= len(dataloader)\n",
    "    total_acc /= len(dataloader)\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    return (total_loss, total_acc, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, feature in enumerate(tqdm(test_loader)):\n",
    "\n",
    "            feature = feature.to(DEVICE)\n",
    "            logits = model(feature)\n",
    "            prediction = (logits >= 0.5).int()\n",
    "            predictions.extend(prediction.tolist())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performace(model, X_train, X_test, y_train, y_test,\n",
    "                     ljust_len=30):\n",
    "    print('Training accuracy: {}'.format(\n",
    "        \"%.4f\" % model.score(X_train, y_train)))\n",
    "\n",
    "    male, female = X_test.gender == 1, X_test.gender == 0\n",
    "    print('Test accuracy:\\n\\t{}{}\\n\\t{}{}\\n\\t{}{}'.format(\n",
    "        'General population'.ljust(ljust_len),\n",
    "        \"%.4f\" % model.score(X_test, y_test),\n",
    "        'Male'.ljust(ljust_len),\n",
    "        \"%.4f\" % model.score(X_test[male], y_test[male]),\n",
    "        'Female'.ljust(ljust_len),\n",
    "        \"%.4f\" % model.score(X_test[female], y_test[female])))\n",
    "\n",
    "    employ_cols = X_test.columns[X_test.columns.str.contains('employStatus')]\n",
    "    for employ_col in employ_cols:\n",
    "        rows = X_test[employ_col] == 1\n",
    "        print('\\t{}{}'.format(\n",
    "            employ_col.split('_')[-1].ljust(ljust_len),\n",
    "            \"%.4f\" % model.score(X_test[rows], y_test[rows])))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print('\\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(file_path, model, optimizer, scaler, scheduler,\n",
    "                    epoch, train_acc, val_acc, precision, recall, f1):\n",
    "\n",
    "    checkpoint = {'epoch': epoch,\n",
    "                  'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'scaler_state_dict': scaler.state_dict(),\n",
    "                  'scheduler_state_dict': scheduler.state_dict(),\n",
    "                  'train_accuray': train_acc, 'val_accuray': val_acc,\n",
    "                  'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    torch.save(checkpoint, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 79.4782%\tTrain Loss 0.6956\t Learning Rate 0.0010000\n",
      "\tVal Acc 78.3854%\tVal Loss 0.6856\n",
      "\tVal Precison 0.8378\tRecall 0.1114\tF1 0.1967\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 80.2065%\tTrain Loss 0.6856\t Learning Rate 0.0010000\n",
      "\tVal Acc 80.1327%\tVal Loss 0.6832\n",
      "\tVal Precison 0.7386\tRecall 0.2529\tF1 0.3768\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 81.1523%\tTrain Loss 0.6808\t Learning Rate 0.0010000\n",
      "\tVal Acc 81.1492%\tVal Loss 0.6772\n",
      "\tVal Precison 0.8250\tRecall 0.2618\tF1 0.3974\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.1484%\tTrain Loss 0.6776\t Learning Rate 0.0010000\n",
      "\tVal Acc 81.1576%\tVal Loss 0.6758\n",
      "\tVal Precison 0.8614\tRecall 0.2462\tF1 0.3829\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 81.9754%\tTrain Loss 0.6780\t Learning Rate 0.0010000\n",
      "\tVal Acc 81.5272%\tVal Loss 0.6765\n",
      "\tVal Precison 0.8198\tRecall 0.2848\tF1 0.4227\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.3772%\tTrain Loss 0.6767\t Learning Rate 0.0010000\n",
      "\tVal Acc 82.7789%\tVal Loss 0.6782\n",
      "\tVal Precison 0.7554\tRecall 0.4064\tF1 0.5285\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.4665%\tTrain Loss 0.6766\t Learning Rate 0.0010000\n",
      "\tVal Acc 81.7372%\tVal Loss 0.6755\n",
      "\tVal Precison 0.8255\tRecall 0.2929\tF1 0.4324\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.5865%\tTrain Loss 0.6763\t Learning Rate 0.0010000\n",
      "\tVal Acc 80.1831%\tVal Loss 0.6794\n",
      "\tVal Precison 0.8849\tRecall 0.1903\tF1 0.3132\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 82.5558%\tTrain Loss 0.6758\t Learning Rate 0.0010000\n",
      "\tVal Acc 81.9052%\tVal Loss 0.6743\n",
      "\tVal Precison 0.8389\tRecall 0.2947\tF1 0.4361\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.0190%\tTrain Loss 0.6745\t Learning Rate 0.0010000\n",
      "\tVal Acc 82.3757%\tVal Loss 0.6751\n",
      "\tVal Precison 0.7751\tRecall 0.3633\tF1 0.4947\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.5045%\tTrain Loss 0.6729\t Learning Rate 0.0005000\n",
      "\tVal Acc 82.1489%\tVal Loss 0.6738\n",
      "\tVal Precison 0.8349\tRecall 0.3095\tF1 0.4516\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.6105%\tTrain Loss 0.6724\t Learning Rate 0.0005000\n",
      "\tVal Acc 82.8881%\tVal Loss 0.6728\n",
      "\tVal Precison 0.8062\tRecall 0.3679\tF1 0.5052\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.6133%\tTrain Loss 0.6725\t Learning Rate 0.0005000\n",
      "\tVal Acc 82.3337%\tVal Loss 0.6733\n",
      "\tVal Precison 0.8232\tRecall 0.3261\tF1 0.4672\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.7612%\tTrain Loss 0.6717\t Learning Rate 0.0005000\n",
      "\tVal Acc 83.3165%\tVal Loss 0.6754\n",
      "\tVal Precison 0.7385\tRecall 0.4606\tF1 0.5673\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.9202%\tTrain Loss 0.6715\t Learning Rate 0.0005000\n",
      "\tVal Acc 82.9469%\tVal Loss 0.6739\n",
      "\tVal Precison 0.7746\tRecall 0.3976\tF1 0.5255\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 83.8979%\tTrain Loss 0.6714\t Learning Rate 0.0005000\n",
      "\tVal Acc 82.7369%\tVal Loss 0.6726\n",
      "\tVal Precison 0.8244\tRecall 0.3470\tF1 0.4884\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.0960%\tTrain Loss 0.6706\t Learning Rate 0.0005000\n",
      "\tVal Acc 82.6361%\tVal Loss 0.6725\n",
      "\tVal Precison 0.8220\tRecall 0.3431\tF1 0.4842\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.1350%\tTrain Loss 0.6703\t Learning Rate 0.0005000\n",
      "\tVal Acc 82.1909%\tVal Loss 0.6738\n",
      "\tVal Precison 0.8276\tRecall 0.3159\tF1 0.4572\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.5647%\tTrain Loss 0.6686\t Learning Rate 0.0002500\n",
      "\tVal Acc 83.1233%\tVal Loss 0.6733\n",
      "\tVal Precison 0.7813\tRecall 0.4018\tF1 0.5307\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.7042%\tTrain Loss 0.6684\t Learning Rate 0.0002500\n",
      "\tVal Acc 82.8881%\tVal Loss 0.6723\n",
      "\tVal Precison 0.8076\tRecall 0.3668\tF1 0.5045\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.9247%\tTrain Loss 0.6674\t Learning Rate 0.0002500\n",
      "\tVal Acc 82.9217%\tVal Loss 0.6721\n",
      "\tVal Precison 0.8166\tRecall 0.3622\tF1 0.5018\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 84.9693%\tTrain Loss 0.6672\t Learning Rate 0.0002500\n",
      "\tVal Acc 82.9301%\tVal Loss 0.6729\n",
      "\tVal Precison 0.7991\tRecall 0.3757\tF1 0.5111\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.0056%\tTrain Loss 0.6667\t Learning Rate 0.0001250\n",
      "\tVal Acc 83.1065%\tVal Loss 0.6721\n",
      "\tVal Precison 0.8086\tRecall 0.3781\tF1 0.5153\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.2148%\tTrain Loss 0.6664\t Learning Rate 0.0001250\n",
      "\tVal Acc 82.9049%\tVal Loss 0.6726\n",
      "\tVal Precison 0.8046\tRecall 0.3700\tF1 0.5069\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.3348%\tTrain Loss 0.6657\t Learning Rate 0.0001250\n",
      "\tVal Acc 83.1485%\tVal Loss 0.6728\n",
      "\tVal Precison 0.7861\tRecall 0.3990\tF1 0.5293\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.4074%\tTrain Loss 0.6656\t Learning Rate 0.0001250\n",
      "\tVal Acc 83.2241%\tVal Loss 0.6718\n",
      "\tVal Precison 0.7999\tRecall 0.3916\tF1 0.5258\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.4436%\tTrain Loss 0.6651\t Learning Rate 0.0000625\n",
      "\tVal Acc 83.0645%\tVal Loss 0.6727\n",
      "\tVal Precison 0.7898\tRecall 0.3909\tF1 0.5230\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.4660%\tTrain Loss 0.6651\t Learning Rate 0.0000625\n",
      "\tVal Acc 83.0897%\tVal Loss 0.6721\n",
      "\tVal Precison 0.8042\tRecall 0.3806\tF1 0.5167\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.5915%\tTrain Loss 0.6645\t Learning Rate 0.0000625\n",
      "\tVal Acc 83.1821%\tVal Loss 0.6721\n",
      "\tVal Precison 0.7965\tRecall 0.3919\tF1 0.5254\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 85.6445%\tTrain Loss 0.6644\t Learning Rate 0.0000625\n",
      "\tVal Acc 82.9721%\tVal Loss 0.6724\n",
      "\tVal Precison 0.8017\tRecall 0.3760\tF1 0.5119\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "best_epoch, best_f1 = 0, 0\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n",
    "\n",
    "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
    "    train_loss, train_acc = train(model,\n",
    "                                  train_loader,\n",
    "                                  criterion,\n",
    "                                  optimizer,\n",
    "                                  scaler)\n",
    "    val_loss, val_acc, precision, recall, f1 = eval(model,\n",
    "                                                    val_loader,\n",
    "                                                    criterion)\n",
    "    scheduler.step(f1)\n",
    "\n",
    "    print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(\n",
    "        train_acc*100, train_loss, curr_lr))\n",
    "    print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(\n",
    "        val_acc*100, val_loss))\n",
    "    print(\"\\tVal Precison {:.04f}\\tRecall {:.04f}\\tF1 {:.04f}\".format(\n",
    "        precision, recall, f1))\n",
    "\n",
    "    wandb.log({\n",
    "        'lr': curr_lr,\n",
    "        'train_acc': train_acc*100,\n",
    "        'train_loss': train_loss,\n",
    "        'val_acc': val_acc*100,\n",
    "        'val_loss': val_loss,\n",
    "        'val_precison': precision,\n",
    "        'val_recall': recall,\n",
    "        'val_f1': f1\n",
    "    })\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    if (f1 < best_f1):\n",
    "        best_f1 = f1\n",
    "        best_epoch = epoch\n",
    "        save_checkpoint(f'{run.id}_best_model.pt', model, optimizer, scaler, scheduler,\n",
    "                        epoch, train_acc, val_acc, precision, recall, f1)\n",
    "        print(f'Best model saved at epoch {epoch}')\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 187/187 [00:00<00:00, 381.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11959"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred = test(model, test_loader)\n",
    "# len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90      9277\n",
      "           1       0.79      0.39      0.52      2682\n",
      "\n",
      "    accuracy                           0.84     11959\n",
      "   macro avg       0.82      0.68      0.71     11959\n",
      "weighted avg       0.83      0.84      0.82     11959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
